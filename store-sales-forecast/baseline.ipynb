{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af597f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8991709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "sample_submit = pd.read_csv('dataset/sample_submit.csv')\n",
    "\n",
    "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "def lag_feature_adv(df, lags, col):\n",
    "    '''\n",
    "    历史N周平移特征\n",
    "    '''\n",
    "    tmp = df[['week','shop_id','item_id',col]]\n",
    "    for i in lags:\n",
    "        shifted = tmp.copy()\n",
    "        shifted.columns = ['week','shop_id','item_id', col+'_lag_'+str(i)+'_adv']\n",
    "        shifted['week'] += i\n",
    "        df = pd.merge(df, shifted, on=['week','shop_id','item_id'], how='left')\n",
    "        df[col+'_lag_'+str(i)+'_adv'] = df[col+'_lag_'+str(i)+'_adv']\n",
    "    return df\n",
    "\n",
    "df = lag_feature_adv(df, [1, 2, 3], 'weekly_sales')\n",
    "\n",
    "x_train = df[df.week < 33].drop(['weekly_sales'], axis=1)\n",
    "y_train = df[df.week < 33]['weekly_sales']\n",
    "x_test = df[df.week == 33].drop(['weekly_sales'], axis=1)\n",
    "\n",
    "\n",
    "def cv_model(clf, train_x, train_y, test_x, clf_name='lgb'):\n",
    "    folds = 5\n",
    "    seed = 1024\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "     \n",
    "    categorical_feature = ['shop_id','item_id','item_category_id']\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "        valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'mse',\n",
    "            'metric': 'mse',\n",
    "            'min_child_weight': 5,\n",
    "            'num_leaves': 2 ** 7,\n",
    "            'lambda_l2': 10,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.9,\n",
    "            'bagging_freq': 4,\n",
    "            'learning_rate': 0.05,\n",
    "            'seed': 1024,\n",
    "            'n_jobs':-1,\n",
    "            'silent': True,\n",
    "            'verbose': -1,\n",
    "        }\n",
    "\n",
    "        model = clf.train(params, train_matrix, 5000, valid_sets=[train_matrix, valid_matrix], \n",
    "                          categorical_feature = categorical_feature,\n",
    "                          verbose_eval=500,early_stopping_rounds=200)\n",
    "        val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "        test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "\n",
    "        train[valid_index] = val_pred\n",
    "        test += test_pred / kf.n_splits\n",
    "        cv_scores.append(mean_squared_error(val_y, val_pred))\n",
    "        \n",
    "        print(cv_scores)\n",
    "       \n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1124030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 0.78069\tvalid_1's l2: 1.82782\n",
      "Early stopping, best iteration is:\n",
      "[334]\ttraining's l2: 0.926092\tvalid_1's l2: 1.81353\n",
      "[1.8135331031876856]\n",
      "************************************ 2 ************************************\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 0.774432\tvalid_1's l2: 1.99476\n",
      "Early stopping, best iteration is:\n",
      "[451]\ttraining's l2: 0.81515\tvalid_1's l2: 1.98946\n",
      "[1.8135331031876856, 1.9894624473183213]\n",
      "************************************ 3 ************************************\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 0.732702\tvalid_1's l2: 2.14006\n",
      "[1000]\ttraining's l2: 0.542256\tvalid_1's l2: 2.07323\n",
      "[1500]\ttraining's l2: 0.453476\tvalid_1's l2: 2.03242\n",
      "Early stopping, best iteration is:\n",
      "[1514]\ttraining's l2: 0.451795\tvalid_1's l2: 2.03053\n",
      "[1.8135331031876856, 1.9894624473183213, 2.030526369997762]\n",
      "************************************ 4 ************************************\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 0.823193\tvalid_1's l2: 1.58409\n",
      "Early stopping, best iteration is:\n",
      "[488]\ttraining's l2: 0.832406\tvalid_1's l2: 1.58169\n",
      "[1.8135331031876856, 1.9894624473183213, 2.030526369997762, 1.581693835140496]\n",
      "************************************ 5 ************************************\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\ttraining's l2: 0.757224\tvalid_1's l2: 1.87426\n",
      "[1000]\ttraining's l2: 0.562419\tvalid_1's l2: 1.87224\n",
      "Early stopping, best iteration is:\n",
      "[808]\ttraining's l2: 0.615423\tvalid_1's l2: 1.85838\n",
      "[1.8135331031876856, 1.9894624473183213, 2.030526369997762, 1.581693835140496, 1.858383279297664]\n",
      "lgb_scotrainre_list: [1.8135331031876856, 1.9894624473183213, 2.030526369997762, 1.581693835140496, 1.858383279297664]\n",
      "lgb_score_mean: 1.8547198069883855\n",
      "lgb_score_std: 0.1583139119743203\n"
     ]
    }
   ],
   "source": [
    "lgb_train, lgb_test = cv_model(lgb, x_train, y_train, x_test)\n",
    "\n",
    "\n",
    "sample_submit['weekly_sales'] = lgb_test\n",
    "sample_submit['weekly_sales'] = sample_submit['weekly_sales'].apply(lambda x:x if x>0 else 0).values\n",
    "sample_submit.to_csv('baseline_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee649a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
